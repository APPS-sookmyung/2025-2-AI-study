# Studying the Practices of Deploying Machine Learning Projects on Docker(2022)


- 이 논문은 ML 기반 소프트웨어 프로젝트에서 도커가 실제로 어떻게 쓰이는지를 대규모로 조사한 연구 결과를 서술하고 있음
- GitHub의 **406개 ML 프로젝트**와 Docker Hub 이미지를 분석해 **사용되는 프로젝트 유형, 목적, Dockerfile 기능, 이미지 특성**을 정리했다.
- 결론: Docker는 **이식성(플랫폼/언어/GPU 런타임 간 이동)**을 크게 개선하지만, **이미지 크기·파일 수·깊은 디렉터리 구조**로 인해 **자원 소모가 커지는 경향**이 있다.

---

## 논문 메타

- **배경**: Docker는 격리·경량·패키징 장점 때문에 현대 소프트웨어 배포의 표준으로 확산. 하지만 **ML 프로젝트만**을 대상으로 한 배포 관행 연구는 부족.
- **목표**: ML 프로젝트에서 Docker가 **어떤 종류의 프로젝트에**, **어떤 목적으로**, **어떤 기능(명령/베이스 이미지)을 통해**, **어떤 이미지 특성**으로 쓰이는지 체계적으로 파악.
- **데이터**: GitHub의 공개 ML 프로젝트 406개 + 해당 Docker Hub 이미지(실제 매니페스트/레이어 분석).
- **구성**: Introduction → Background → Methodology → Results(RQ1–RQ4) → Related Work → Threats to Validity → Conclusion/Future Work.

---

## 개요

- 도커는 실행이 가볍고 빠르며, 이미지/레지스트리를 통해 손쉽게 버전 관리·공유 가능해 소프트웨어 배포에 자주 쓰이고 있음
- 기존 연구는 일반 소프트웨어에 집중, ML 프로젝트에서의 도커 실제 사용 동향은 잘 알려져 있지 않음
- 본 연구는 탐색적 연구(empirical exploratory)로, ML 프로젝트 배포에서 도커 사용 실태를 분석

---

## 연구 방법

- **데이터 수집**: GitHub의 ML 기반 오픈소스 프로젝트 중 Docker Hub에 실제 이미지가 존재하는 프로젝트 406개를 수집
- **연구 질문(RQ) 설계**: 4개의 연구 질문을 정의하고, 정량 분석(명령/베이스 이미지/매니페스트·레이어 통계)과 정성 코딩(오픈 코딩)으로 범주화.
  1. **RQ1**: 어떤 종류의 ML 프로젝트에서 도커를 쓰는가?
  2. **RQ2**: 도커를 어떤 목적으로 쓰는가?
  3. **RQ3**: 어떤 Docker 기능을 쓰는가? (Dockerfile 분석)
  4. **RQ4**: 이미지 특성은 어떤가? (타깃 아키텍처/OS, 레이어 파일 수·디렉터리 깊이, 환경변수, 구성 파일 크기 등) 분석
- **분석 방식** : 정량 분석, 정성 분석 혼합 방식
  - 정량 분석: 정량 분석: Dockerfile 명령어, 베이스 이미지, 레이어 수, 매니페스트 크기 같은 숫자 데이터 분석.
  - 정성 분석: 정성 분석: 프로젝트를 직접 보고 성격(유형, 목적)을 사람이 코딩/분류.
---

## 연구 결과

### RQ1. 어떤 종류의 ML 프로젝트에서 도커를 쓰는가?

- 6가지 카테고리로 라벨링:
  - **Application System(애플리케이션)** — 약 42%
  - **AIOps/MLOps** — 약 23%
  - **Toolkits(데이터 처리용)** — 약 16%
  - **DL Frameworks** — 약 15%
  - **Models(특정 모델 자체)** — 약 13%
  - **Tutorials/Documentation** — 약 1%
- 애플리케이션형이 가장 많고, 운영 자동화 및 툴킷/프레임워크에도 활발히 컨테이너화.


### RQ2. 도커를 어떤 목적으로 쓰는가?

- 21개의 목적을 정의 가능했음, 아래는 대표적인 예시
  - **Data management**: 데이터 준비/적재/전처리 파이프라인
  - **Interactive development**: Jupyter등의 개발 환경 제공
  - **Task scheduling**: 학습/추론/배치 실행 관리
  - **Model management**: 모델 학습, 테스트, 추론, 버전 관리
- Docker는 플랫폼 간 이식성과 환경 일관성을 제공하여 ML 워크로드 이동성을 높인다.

### RQ3. 어떤 Docker 기능을 쓰는가? (Dockerfile 분석)

- **명령 사용 패턴**
  - 가장 많이 쓰인 명령: `RUN`
    - 주로 파일시스템 조작, 의존성 설치, 권한/소유권 설정, 빌드/실행 스크립트, 환경 설정 수행에 사용
  - 기타: `ADD`, `CMD`, `COPY`, `ENTRYPOINT`, `EXPOSE`, `USER`, `VOLUME` 등
- **베이스 이미지 유형**
  - **OS 계열**: Ubuntu, Debian 등
  - **GPU용 런타임**: CUDA 등
  - **언어 런타임**: Python, Node.js 등
  - **ML 플랫폼**: 딥러닝 프레임워크 이미지(TensorFlow/PyTorch 등), AutoML/Online ML 기반 이미지
- **멀티-스테이지/다중 `FROM`**: 여러 `FROM`을 한 Dockerfile에서 사용하는 사례가 다수 관찰(빌드/런타임 분리, 크기 최적화 목적)

### RQ4. 이미지 특성은 어떤가? (manifest, layer 분석)

- **타깃 플랫폼 다양성**: 서로 다른 OS/하드웨어 아키텍처(x86-64, ARM 등)를 목표로 빌드된 이미지 다수. Edge/IoT(라즈베리 파이) 타깃 사례도 확인
- **구성 파일 크기**: image manifest의 중앙값 ≈ 약 11MB (카테고리별 차이 존재)
- **파일 수·디렉터리 깊이**: 이미지 레이어의 파일 수가 매우 많고(샘플의 90%가 5만 개 이상), 최대 하위 디렉터리 깊이가 16 초과인 경우가 흔함
- **공간 집중**: 소수의 큰 파일이 이미지 용량 대부분을 차지하는 경향이 있음
- **실행 시 변수**: 환경변수(동적 키)가 5개 이상 달리는 등 런타임 구성ㅇ; 다양
- **결과 해석**: 전통 소프트웨어 대비 ML 이미지가 더 크고 복잡해 실행에 더 많은 자원(스토리지/메모리/네트워크)이 필요할 수 있음

---

## 논의 & 시사점

- **이식성·재현성 극대화**: OS/언어/GPU 제약을 우회해 동일 컨테이너로 이동·재현 가능.
- 이미지가 너무 크고 복잡해 생기는 문제가 많음
  - 권장 해결법: 멀티 스테이지 빌드, slim/distroless 베이스, 캐시/빌드 아티팩트 제거, 레이어 수 축소, 모델/데이터를 외부 볼륨/스토리지로 분리
- **플랫폼 타깃 명확화**: x86/ARM, GPU/CUDA 버전 호환을 명시하고 태깅 전략 수립.
- **운영 자동화**: 태그/다이제스트 기반 배포, CI/CD와 연계해 테스트 일관성 확보.
- **보안/권한**: `USER` 지시어 사용, rootless, 최소 권한, `read-only` 루트, 이미지 스캐닝 권장.

---

## 기존 연구와의 차별점

- 기존의 일반 소프트웨어 컨테이너 연구 대비, 본 논문은 ML 특유의 의존성, GPU 런타임, 프레임워크 기반의 사용 행태를 별도로 조명
- 기존 논문: 일반 이미지의 파일 수·디렉터리 깊이는 상대적으로 작다
- 본 논문: 기존과 상반된 결과를 제시, ML 이미지는 훨씬 크고 계층이 깊다

---

## 한계

- 연구 대상이 GitHub, Docker Hub의 오픈소스 프로젝트에 한정되어 있어 사내/상용 프로젝트와 차이가 날 수 있음
- 프로젝트 유형, 목적 분류 시 분류자의 주관이 개입될 수 있음
- 2022년 시점의 스냅샷 분석 결과이므로 도구/최적화 관행은 시간이 지나며 변할 수 있음

---

## 결론 & 앞으로의 연구

- 도커는 ML 프로젝트 배포에서 사실상 표준 도구로 사용되는 중, 이식성/재현성을 크게 높인다
- 이미지 복잡도·크기 문제를 해결하기 위해 효율적 저장/전송·경량화 기법 연구 필요
- 후속 연구: 더 넓은 생태계(사설 레지스트리, 상용 워크로드), 성능·보안 영향, MLOps 파이프라인 통합 효과 등을 정량적으로 탐구할 여지