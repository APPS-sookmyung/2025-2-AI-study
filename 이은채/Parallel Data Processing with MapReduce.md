# Parallel Data Processing with MapReduce: A Survey(2011)

## 배경

- 데이터가 폭발적으로 증가하면서 빅데이터 처리를 위한 새로운 모델이 필요해졌다
- 전통적인 DBMS나 단일 서버로는 처리 속도와 저장 용량의 한계가 있었음
- Google이 웹 검색 색인, 로그 분석 등에서 효율적인 분산 처리를 위해 MapReduce 모델을 제안
- 목표: 프로그래머가 분산 시스템 세부사항(분할, 오류 복구, 스케줄링 등)을 신경 쓰지 않고도 병렬 프로그래밍 가능하게 하기

---

## 특징

- 프로그래밍 모델 + 실행 프레임워크
  - 사용자는 `map`과 `reduce` 함수만 정의
  - 시스템이 데이터 분할, 분산 처리, 오류 복구를 자동 관리

- Shared-Nothing 구조
  - 여러 독립 노드(PC)들이 네트워크로 연결된 분산 환경

- 확장성(Scalability)
  - 수천 개 노드로 확장 가능 → 대규모 데이터 처리 가능

- 내고장성(Fault Tolerance)
  - 데이터 복제(Replication) 및 태스크 재실행을 통해 장애 대응

- 데이터 저장
  - Google의 GFS(Google File System), Hadoop의 HDFS 같은 분산 파일 시스템 위에서 동작

---

## 기본 함수

- Map(key1, value1) > (key2, value2)
  - 입력 데이터를 (key, value) 쌍으로 변환

- Reduce(key2, list(value2)) > (key3, value3)
  - 같은 key2를 가진 value 리스트를 합쳐 최종 결과 도출

---

## 실행 흐름
1. 입력 데이터를 청크 단위로 분할해 분산 파일 시스템에 저장
2. Map 단계: 각 Mapper가 데이터를 읽고 (key2, value2) 쌍 생성
3. Shuffle & Sort 단계: 같은 key2끼리 데이터를 모아 정렬
4. Reduce 단계: key2별 value 리스트를 집계하여 최종 결과 출력
5. 결과는 다시 분산 파일 시스템에 저장
6. 선택적으로 Combiner를 두어 Mapper 출력에서 pre-aggregation 가능

---

## 장점
- 단순하고 사용이 편리: 두 함수만 작성하면 병렬 처리 가능
- 유연성: 특정 스키마나 SQL 같은 질의 언어에 제한되지 않음
- 저장 구조 독립성: 다양한 파일 시스템/저장소에서 동작 가능
- 내고장성: 장애 발생 시 자동 복구
- 높은 확장성: 저가 범용 서버를 추가해 쉽게 scale-out 가능

---

## 단점
- 고정된 단일 데이터 흐름: Join, 반복 연산(loop) 같은 복잡한 알고리즘 표현 어려움
- 기능 부족: 스키마, 인덱스, 질의 최적화 기능 없음
- 성능이 상대적으로 낮음: 중간 결과를 디스크에 기록해야 해서 I/O 비용 큼, 모든 Map이 끝나야 Reduce 시작 > 느린 노드(straggler)가 전체 실행 시간 지연
- 시스템 환경 부족: DBMS와 비교해 도구·생태계가 덜 발달

---